2025-09-17 01:40:10,323 - __main__ - INFO - Loaded .env file
2025-09-17 01:40:10,324 - __main__ - INFO - Found GROQ_API_KEY (first 5 chars): gsk_c...
2025-09-17 01:40:10,324 - __main__ - INFO - Importing LLM client...
2025-09-17 01:40:11,103 - __main__ - INFO - Testing LLM client...
2025-09-17 01:40:11,103 - __main__ - INFO - Input text length: 296 characters
2025-09-17 01:40:11,103 - __main__ - INFO - Testing prompt building...
2025-09-17 01:40:11,103 - __main__ - INFO - Prompt built successfully. Length: 505 characters
2025-09-17 01:40:11,103 - __main__ - DEBUG - Prompt: You are an assistant creating a concise handoff summary between two human agents. Summarize the following caller context in 2-3 short sentences, focusing on intent, status, and next steps.

Context:

    Caller: Hi, I'm having trouble with my internet connection.
    Agent: I can help with that. Have you tried restarting your router?
    Caller: Yes, I've tried that but it's still not working.
    Agent: Let's check your network settings. Can you tell me what lights are on your router?
    

Summary:
2025-09-17 01:40:11,104 - __main__ - INFO - Generating summary...
2025-09-17 01:40:11,104 - services.llm_client - INFO - Starting summary generation...
2025-09-17 01:40:11,104 - services.llm_client - INFO - Starting summary generation
2025-09-17 01:40:11,105 - services.llm_client - INFO - Initializing Groq client...
2025-09-17 01:40:11,105 - services.llm_client - DEBUG - Using API key: gsk_c...vq0Zi
2025-09-17 01:40:11,606 - services.llm_client - INFO - Sending request to Groq API...
2025-09-17 01:40:11,606 - services.llm_client - DEBUG - Using model: llama-3.1-8b-instant
2025-09-17 01:40:11,606 - services.llm_client - DEBUG - Prompt length: 565 characters
2025-09-17 01:40:11,606 - services.llm_client - DEBUG - Sending request to Groq API with timeout: 30s
2025-09-17 01:40:11,634 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are an assistant creating a concise handoff summary between two human agents. Focus on key points, next steps, and any important context.'}, {'role': 'user', 'content': "\n        Please provide a concise handoff summary of the following conversation between a caller and an agent.\n        Focus on key points, issues, and next steps. Keep it brief but informative.\n        \n        Conversation:\n        \n    Caller: Hi, I'm having trouble with my internet connection.\n    Agent: I can help with that. Have you tried restarting your router?\n    Caller: Yes, I've tried that but it's still not working.\n    Agent: Let's check your network settings. Can you tell me what lights are on your router?\n    \n        \n        Summary:\n        "}], 'model': 'llama-3.1-8b-instant', 'max_tokens': 300, 'stream': False, 'temperature': 0.2, 'top_p': 1.0}, 'idempotency_key': 'stainless-python-retry-b6e4729e-87a6-417f-a750-c519b2afe622'}
2025-09-17 01:40:11,674 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-17 01:40:11,674 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=30 socket_options=None
2025-09-17 01:40:11,775 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014A94184D90>
2025-09-17 01:40:11,775 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014A91F2AC30> server_hostname='api.groq.com' timeout=30
2025-09-17 01:40:11,858 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014A94184F50>
2025-09-17 01:40:11,858 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-17 01:40:11,858 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-17 01:40:11,858 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-17 01:40:11,858 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-17 01:40:11,858 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-17 01:40:12,266 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 16 Sep 2025 20:10:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5813'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.87s'), (b'x-request-id', b'req_01k5a2cbnbfxq9j3pxrz1xtrsf'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EVBgG1AqNcOGhMU4WWSzICGoGBoc3oWKQM15D.vhSPg-1758053412-1.0.1.1-N2KE5d1GMk8yruTkNNSnsbEdVQ7hw.VTiSt0Vuxz8qhHjSxv8v1mO3F9nIYLhjZ1RSSxXktwXFy2n9_R6nOLdsv88kqJr3R0NeRb4n5ayyg; path=/; expires=Tue, 16-Sep-25 20:40:12 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980301840a2c85de-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-17 01:40:12,267 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-17 01:40:12,268 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-17 01:40:12,268 - httpcore.http11 - DEBUG - response_closed.started
2025-09-17 01:40:12,268 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-17 01:40:12,268 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 16 Sep 2025 20:10:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5813', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.87s', 'x-request-id': 'req_01k5a2cbnbfxq9j3pxrz1xtrsf', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=EVBgG1AqNcOGhMU4WWSzICGoGBoc3oWKQM15D.vhSPg-1758053412-1.0.1.1-N2KE5d1GMk8yruTkNNSnsbEdVQ7hw.VTiSt0Vuxz8qhHjSxv8v1mO3F9nIYLhjZ1RSSxXktwXFy2n9_R6nOLdsv88kqJr3R0NeRb4n5ayyg; path=/; expires=Tue, 16-Sep-25 20:40:12 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '980301840a2c85de-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-17 01:40:12,283 - services.llm_client - DEBUG - API usage - Prompt tokens: 178, Completion tokens: 131, Total tokens: 309
2025-09-17 01:40:12,283 - services.llm_client - INFO - Successfully generated summary in 1.18s
2025-09-17 01:40:12,283 - services.llm_client - DEBUG - Generated summary: **Handoff Summary**

**Case:** Troubleshooting Internet Connection Issue

**Key Points:**

- Caller ...
2025-09-17 01:40:12,284 - __main__ - INFO - ================================================================================
2025-09-17 01:40:12,284 - __main__ - INFO - SUMMARY GENERATION COMPLETED
2025-09-17 01:40:12,284 - __main__ - INFO - Duration: 1.18 seconds
2025-09-17 01:40:12,284 - __main__ - INFO - --------------------------------------------------------------------------------
2025-09-17 01:40:12,285 - __main__ - INFO - Generated summary: **Handoff Summary**

**Case:** Troubleshooting Internet Connection Issue

**Key Points:**

- Caller is experiencing internet connection issues despite restarting the router.
- Caller has already attempted the basic troubleshooting step of restarting the router.

**Issues:**

- Internet connection is not stable.
- No further troubleshooting steps have been taken beyond restarting the router.

**Next Steps:**

- Ask the next agent to inquire about the router's lights to determine if there are any hardware issues.
- Consider further troubleshooting steps, such as checking the modem or service provider's status.
- Escalate the issue if necessary to ensure a timely resolution for the customer.
2025-09-17 01:40:12,285 - __main__ - INFO - ================================================================================
